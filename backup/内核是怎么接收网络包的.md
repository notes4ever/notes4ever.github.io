> **《深入理解Linux网络 张彦飞》学习笔记。**

大致总结，当数据到来以后，第⼀个迎接它的是⽹卡：

- ⽹卡将数据帧DMA到内存的RingBuffer中，然后向CPU发起中断通知。
- CPU响应中断请求，调⽤⽹卡启动时注册的中断处理函数。 
- 中断处理函数⼏乎没⼲什么，只发起了软中断请求。 
- 内核线程ksoftirqd发现有软中断请求到来，先关闭硬中断。
- ksoftirad线程开始调⽤网卡驱动的poll函数收包。
- poll函数将收到的包送到协议栈注册的ip_rcv函数中。
- ip_rcv函数将包送到udp_rcv函数中（对于TCP包是送到tcp_rcv_v4）。

## RingBuffer到底是什么，RingBuffer为什么会丢包？
RingBuffer这个数据结构包括igb_rx_buffer环形队列数组、e1000_adv_rx_desc环形队列数组及众多的skb，如下图所示：

![image](https://github.com/user-attachments/assets/2f839213-6d80-4d50-ba2d-5f3e566c6b8f)

网卡在收到数据的时候以DMA的方式将包写到RingBuffer中。

软中断收包的时候来这里把skb取走，并申请新的skb重新挂上去。

RingBuffer中指针数组是预先分配好的，而skb虽然也会预先分配好，但是在后面收包过程中会不断动态地分配申请。

如果内核处理得不及时导致RingBuffer满了，那后面新来的数据包就会被丢弃。

## 网络相关的硬中断、软中断都是什么？
在网卡将数据放到RingBuffer中后，接着就发起硬中断，通知CPU进行处理。

不过硬中断的上下文里做的工作很少，将传过来的poll_list添加到了Per-CPU变量softnet_data的poll_list里（softnet_data的poll_list是一个双向列表，其中的设备都带有输入帧等着被处理），接着触发软中断NET_RX_SOFTIRQ。

在软中断中对softnet_data的设备列表poll_list进行遍历，执行完卡驱动提供的poll来收取网络包。处理完后会送到协议栈的ip_rcv、udp_rcv、tcp_rcv_v4等函数中。

## Linux里的ksoftirqd内核线程是干什么的？
一台两核的虚拟机上有两个ksoftirqd内核线程。机器上有几个核，内核就会创建几个ksoftirqd线程出来。

内核线程ksoftirqd包含了所有的软中断处理函数，也包括这里提到的NET_RX_SOFTIRQ。在__do_softirq中根据软中断的类型，执行不同的处理函数。对于软中断NET_RX_SOFTIRQ来说是net_rx_action函数。

## 为什么网卡开启多队列能提升网络性能？
每个队列都会有独立的、不同的中断号，而中断号亲和的CPU不同，不同的队列在将数据收到自己的RingBuffer后，可以分别向不同的CPU发起硬中断通知。

而在硬中断的处理中，调用__raise_softirq_irqoff发起软中断的时候，是基于当前CPU核心smp_processor_id的（__raise_softirq_irqoff => or_softirq_pending => local_softirq_pending），**哪个核响应的硬中断，那么该硬中断发起的软中断任务就必然由这个核来处理**，所以在工作实践中，如果网络包的接收频率高而导致个别核si偏高，那么通过加大网卡队列数，并设置每个队列中断号上的smp_affinity，将各个队列的硬中断打散到不同的CPU上就行了。这样硬中断后面的软中断CPU开销也将由多个核来分担。

## 网络接收过程中的CPU开销如何查看？
在网络的接收过程中，主要工作集中在硬中断和软中断上，二者的消耗都可以通过top命令来查看。

其中hi是CPU处理硬中断的开销，si是处理软中断的开销，都是以百分比的形式来展示的。

如果发现某个核的si过高，那么很有可能你的业务上当前数据包的接收已经非常频繁了，需要通过上面说的多队列网卡配置让其他核参与进来，分担这个核接收包的内核工作量。

## 参考资料

- https://joytsing.cn/posts/20149/